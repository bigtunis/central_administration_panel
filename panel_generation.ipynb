{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3f3cb9c-425a-4e40-a303-b828936d23d2",
   "metadata": {},
   "source": [
    "# Function that generate panel data from raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42b7e0f-4f77-4b87-a2df-dc408938c40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import recordlinkage\n",
    "from recordlinkage.preprocessing import clean\n",
    "import matplotlib.pyplot as plt\n",
    "from fuzzywuzzy import fuzz\n",
    "import seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21c971d-aa6b-44de-a90e-d2b7bc8eb165",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"input/raw_data_clean.csv\", sep=\";\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f5051b-a24b-4b0d-a8a2-6e6899e24399",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_panel_data(df):\n",
    "    \"\"\"\n",
    "    Create panel data from a single DataFrame containing multiple years.\n",
    "    Assigns consistent person IDs across years using name matching.\n",
    "    \n",
    "    Parameters:\n",
    "    df: DataFrame with columns 'year', 'name', 'ministry', 'position', 'abbreviated_name', \n",
    "                              'is_abbreviated'\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame with added 'person_id' column\n",
    "    \"\"\"\n",
    "    # Make a copy of the input data\n",
    "    df_panel = df.copy()\n",
    "    \n",
    "    # Sort by year to ensure we process in chronological order\n",
    "    df_panel = df_panel.sort_values('year')\n",
    "    \n",
    "    # Get unique years in ascending order\n",
    "    years = sorted(df_panel['year'].unique())\n",
    "    \n",
    "    # Initialize person_id for the first year\n",
    "    first_year_data = df_panel[df_panel['year'] == years[0]]\n",
    "    first_year_indices = first_year_data.index\n",
    "    \n",
    "    # Assign initial person IDs (1 to n) for the first year\n",
    "    df_panel.loc[first_year_indices, 'person_id'] = range(1, len(first_year_indices) + 1)\n",
    "    \n",
    "    # Process each subsequent year\n",
    "    for i in range(1, len(years)):\n",
    "        current_year = years[i]\n",
    "        prev_year = years[i-1]\n",
    "        \n",
    "        print(f\"\\nProcessing year {current_year}...\")\n",
    "        \n",
    "        # Get data for the current and previous years\n",
    "        prev_year_data = df_panel[df_panel['year'] == prev_year].copy()\n",
    "        current_year_data = df_panel[df_panel['year'] == current_year].copy()\n",
    "        \n",
    "        # Clean names\n",
    "        prev_year_data['clean_name'] = clean(prev_year_data['name'])\n",
    "        current_year_data['clean_name'] = clean(current_year_data['name'])\n",
    "        \n",
    "        # Reset indices for matching\n",
    "        prev_year_data = prev_year_data.reset_index()\n",
    "        current_year_data = current_year_data.reset_index()\n",
    "        \n",
    "        # Store original indices for updating the main DataFrame later\n",
    "        orig_indices = {i: row['index'] for i, row in current_year_data.iterrows()}\n",
    "        \n",
    "        # ----- NAME SIMILARITY PREPROCESSING -----\n",
    "        \n",
    "        # Pre-compute all pairwise name similarities\n",
    "        all_name_similarities = {}\n",
    "        for curr_idx, curr_row in current_year_data.iterrows():\n",
    "            for prev_idx, prev_row in prev_year_data.iterrows():\n",
    "                # Calculate token sort ratio for better handling of name component ordering\n",
    "                similarity = fuzz.token_sort_ratio(curr_row['name'], prev_row['name'])\n",
    "                all_name_similarities[(curr_idx, prev_idx)] = similarity / 100.0  # Normalize to 0-1\n",
    "                \n",
    "                # If the similarity is too low (< 50%), we won't consider this a potential match\n",
    "                if similarity < 50:\n",
    "                    all_name_similarities[(curr_idx, prev_idx)] = 0.0\n",
    "        \n",
    "        # Initialize person IDs for current year\n",
    "        current_year_person_ids = pd.Series([None] * len(current_year_data), index=current_year_data.index)\n",
    "        \n",
    "        # Track which person IDs from previous year have already been assigned\n",
    "        used_prev_ids = set()\n",
    "        \n",
    "        # Track which current indices have been matched\n",
    "        matched_current_indices = set()\n",
    "        \n",
    "        ### STEP 1: WITHIN MINISTRY NAME MATCHING ###\n",
    "        print(\"Step 1: Within ministry name matching...\")\n",
    "        \n",
    "        # Create an indexer for within-ministry matching\n",
    "        indexer = recordlinkage.Index()\n",
    "        indexer.block('ministry')\n",
    "        candidate_links_within_ministry = indexer.index(current_year_data, prev_year_data)\n",
    "        \n",
    "        # Create a comparison object\n",
    "        comparison_within = recordlinkage.Compare()\n",
    "        \n",
    "        # Define comparison methods for different fields\n",
    "        comparison_within.string('abbreviated_name', 'abbreviated_name', method='jarowinkler', threshold=0.9)\n",
    "        comparison_within.exact('ministry', 'ministry')\n",
    "        \n",
    "        # Compute features\n",
    "        features_within = comparison_within.compute(candidate_links_within_ministry, current_year_data, prev_year_data)\n",
    "        \n",
    "        # Add custom name similarity\n",
    "        name_similarities = []\n",
    "        for idx_pair in candidate_links_within_ministry:\n",
    "            name_similarities.append(all_name_similarities.get(tuple(idx_pair), 0.0))\n",
    "        \n",
    "        features_within['name_sim'] = name_similarities\n",
    "        \n",
    "        # Only continue with pairs that have some name similarity\n",
    "        valid_pairs = features_within['name_sim'] > 0\n",
    "        features_within = features_within[valid_pairs]\n",
    "        candidate_links_within_ministry = candidate_links_within_ministry[valid_pairs]\n",
    "        \n",
    "        if len(features_within) > 0:\n",
    "            # Add the candidate pairs to the features dataframe for easier reference\n",
    "            features_within['current_idx'] = [pair[0] for pair in candidate_links_within_ministry]\n",
    "            features_within['prev_idx'] = [pair[1] for pair in candidate_links_within_ministry]\n",
    "            \n",
    "            # Calculate total score - no position factor here\n",
    "            features_within['total_score'] = features_within['name_sim'] * 2.0  # Double weight for name\n",
    "            \n",
    "            # Add bonuses for exact matches\n",
    "            if 'ministry' in features_within.columns:\n",
    "                features_within['total_score'] += features_within['ministry'] * 0.5\n",
    "                \n",
    "            if 'abbreviated_name' in features_within.columns:\n",
    "                features_within['total_score'] += features_within['abbreviated_name'] * 0.5\n",
    "            \n",
    "            # Adjusted threshold since we removed position\n",
    "            threshold = 1.5  # Lowered from 2.0\n",
    "            \n",
    "            # Sort by total score to ensure best matches are processed first\n",
    "            features_within = features_within.sort_values('total_score', ascending=False)\n",
    "            \n",
    "            # Process pairs in order of match quality\n",
    "            for idx, row in features_within.iterrows():\n",
    "                if row['total_score'] <= threshold:\n",
    "                    continue\n",
    "                    \n",
    "                current_idx = int(row['current_idx'])\n",
    "                prev_idx = int(row['prev_idx'])\n",
    "                \n",
    "                # Skip if current record already matched or previous person already matched\n",
    "                prev_id = prev_year_data.loc[prev_idx, 'person_id']\n",
    "                if current_idx in matched_current_indices or prev_id in used_prev_ids:\n",
    "                    continue\n",
    "                \n",
    "                # Final name similarity check\n",
    "                name_sim = all_name_similarities.get((current_idx, prev_idx), 0)\n",
    "                if name_sim < 0.5:\n",
    "                    print(f\"Rejecting match due to low name similarity ({name_sim}): {current_year_data.loc[current_idx, 'name']} vs {prev_year_data.loc[prev_idx, 'name']}\")\n",
    "                    continue\n",
    "                \n",
    "                # Assign person ID from previous year\n",
    "                current_year_person_ids[current_idx] = prev_id\n",
    "                \n",
    "                # Mark as matched\n",
    "                used_prev_ids.add(prev_id)\n",
    "                matched_current_indices.add(current_idx)\n",
    "        \n",
    "        ### STEP 2: WITHIN MINISTRY ABBREVIATED_NAME TO NAME MATCHING ###\n",
    "        print(\"Step 2: Within ministry abbreviated name to name matching...\")\n",
    "        \n",
    "        # Identify unmatched records from current year that have is_abbreviated = True\n",
    "        unmatched_indices = current_year_data.index[\n",
    "            (current_year_person_ids.isna()) &\n",
    "            (current_year_data['is_abbreviated'] == True)\n",
    "        ]\n",
    "        \n",
    "        if len(unmatched_indices) > 0:\n",
    "            # Find records from previous year where is_abbreviated = False\n",
    "            prev_year_not_abbreviated = prev_year_data[prev_year_data['is_abbreviated'] == False]\n",
    "            \n",
    "            # Create pairs for potential matches (only within same ministry)\n",
    "            matches_count = 0\n",
    "            \n",
    "            for curr_idx in unmatched_indices:\n",
    "                curr_row = current_year_data.loc[curr_idx]\n",
    "                curr_ministry = curr_row['ministry']\n",
    "                curr_name = curr_row['name']\n",
    "                \n",
    "                # Find potential matches in prev year (same ministry, not abbreviated, not used)\n",
    "                potential_matches = prev_year_not_abbreviated[\n",
    "                    (prev_year_not_abbreviated['ministry'] == curr_ministry) &\n",
    "                    (~prev_year_not_abbreviated['person_id'].isin(used_prev_ids))\n",
    "                ]\n",
    "                \n",
    "                best_match_idx = None\n",
    "                best_match_score = 0.0\n",
    "                \n",
    "                for prev_idx, prev_row in potential_matches.iterrows():\n",
    "                    # Compare curr_name with prev_abbreviated_name\n",
    "                    name_sim = fuzz.token_sort_ratio(curr_name, prev_row['abbreviated_name']) / 100.0\n",
    "                    \n",
    "                    if name_sim >= 0.6 and name_sim > best_match_score:\n",
    "                        best_match_idx = prev_idx\n",
    "                        best_match_score = name_sim\n",
    "                \n",
    "                if best_match_idx is not None:\n",
    "                    prev_id = prev_year_data.loc[best_match_idx, 'person_id']\n",
    "                    \n",
    "                    print(f\"Abbreviated match within ministry: {curr_row['name']} -> {prev_year_data.loc[best_match_idx, 'name']} ({prev_year_data.loc[best_match_idx, 'abbreviated_name']})\")\n",
    "                    \n",
    "                    current_year_person_ids[curr_idx] = prev_id\n",
    "                    used_prev_ids.add(prev_id)\n",
    "                    matched_current_indices.add(curr_idx)\n",
    "                    matches_count += 1\n",
    "            \n",
    "            print(f\"Step 2: Matched {matches_count} records using abbreviated name within ministry.\")\n",
    "        \n",
    "        ### STEP 3: CROSS-MINISTRY NAME MATCHING ###\n",
    "        print(\"Step 3: Cross-ministry name matching...\")\n",
    "        \n",
    "        # Identify remaining unmatched records\n",
    "        unmatched_indices = current_year_data.index[~current_year_data.index.isin(matched_current_indices)]\n",
    "        \n",
    "        if len(unmatched_indices) > 0:\n",
    "            unmatched_data = current_year_data.loc[unmatched_indices]\n",
    "            \n",
    "            # Create a new indexer for cross-ministry matching\n",
    "            cross_indexer = recordlinkage.Index()\n",
    "            cross_indexer.full()  # Compare all pairs\n",
    "            cross_candidate_links = cross_indexer.index(unmatched_data, prev_year_data)\n",
    "            \n",
    "            # Create stricter comparison for cross-ministry\n",
    "            cross_comparison = recordlinkage.Compare()\n",
    "            cross_comparison.string('abbreviated_name', 'abbreviated_name', method='jarowinkler', threshold=0.95)\n",
    "            \n",
    "            # Compute features\n",
    "            cross_features = cross_comparison.compute(cross_candidate_links, unmatched_data, prev_year_data)\n",
    "            \n",
    "            # Add custom name similarity\n",
    "            cross_name_similarities = []\n",
    "            for idx_pair in cross_candidate_links:\n",
    "                cross_name_similarities.append(all_name_similarities.get(tuple(idx_pair), 0.0))\n",
    "            \n",
    "            cross_features['name_sim'] = cross_name_similarities\n",
    "            \n",
    "            # Even stricter name similarity for cross-ministry (minimum 70%)\n",
    "            valid_pairs = cross_features['name_sim'] >= 0.7\n",
    "            cross_features = cross_features[valid_pairs]\n",
    "            cross_candidate_links = cross_candidate_links[valid_pairs]\n",
    "            \n",
    "            if len(cross_features) > 0:\n",
    "                # Add candidate pairs to features\n",
    "                cross_features['current_idx'] = [pair[0] for pair in cross_candidate_links]\n",
    "                cross_features['prev_idx'] = [pair[1] for pair in cross_candidate_links]\n",
    "                \n",
    "                # Calculate total score - no position factor\n",
    "                cross_features['total_score'] = cross_features['name_sim'] * 3.0  # Triple weight for name\n",
    "                \n",
    "                if 'abbreviated_name' in cross_features.columns:\n",
    "                    cross_features['total_score'] += cross_features['abbreviated_name'] * 0.5\n",
    "                \n",
    "                # Adjusted threshold\n",
    "                threshold = 2.5  # Lowered from 3.0\n",
    "                \n",
    "                # Sort by total score\n",
    "                cross_features = cross_features.sort_values('total_score', ascending=False)\n",
    "                \n",
    "                # Process pairs in order of match quality\n",
    "                matches_count = 0\n",
    "                for idx, row in cross_features.iterrows():\n",
    "                    if row['total_score'] <= threshold:\n",
    "                        continue\n",
    "                        \n",
    "                    current_idx = int(row['current_idx'])\n",
    "                    prev_idx = int(row['prev_idx'])\n",
    "                    \n",
    "                    # Skip if previous person already matched\n",
    "                    prev_id = prev_year_data.loc[prev_idx, 'person_id']\n",
    "                    if prev_id in used_prev_ids:\n",
    "                        continue\n",
    "                    \n",
    "                    # Double-check name similarity\n",
    "                    if all_name_similarities.get((current_idx, prev_idx), 0) < 0.7:\n",
    "                        print(f\"Rejecting cross-ministry match due to low name similarity: {unmatched_data.loc[current_idx, 'name']} vs {prev_year_data.loc[prev_idx, 'name']}\")\n",
    "                        continue\n",
    "                    \n",
    "                    # Assign person ID\n",
    "                    current_year_person_ids[current_idx] = prev_id\n",
    "                    \n",
    "                    # Mark as matched\n",
    "                    used_prev_ids.add(prev_id)\n",
    "                    matched_current_indices.add(current_idx)\n",
    "                    matches_count += 1\n",
    "                \n",
    "                print(f\"Step 3: Matched {matches_count} records using cross-ministry name matching.\")\n",
    "        \n",
    "        ### STEP 4: CROSS-MINISTRY ABBREVIATED_NAME TO NAME MATCHING ####\n",
    "        print(\"Step 4: Cross-ministry abbreviated name to name matching...\")\n",
    "        \n",
    "        # Identify remaining unmatched records that are abbreviated\n",
    "        unmatched_indices = current_year_data.index[\n",
    "            (~current_year_data.index.isin(matched_current_indices)) &\n",
    "            (current_year_data['is_abbreviated'] == True)\n",
    "        ]\n",
    "        \n",
    "        if len(unmatched_indices) > 0:\n",
    "            # Find records from previous year that are not abbreviated and not used\n",
    "            prev_year_not_abbreviated = prev_year_data[\n",
    "                (prev_year_data['is_abbreviated'] == False) &\n",
    "                (~prev_year_data['person_id'].isin(used_prev_ids))\n",
    "            ]\n",
    "            \n",
    "            matches_count = 0\n",
    "            \n",
    "            for curr_idx in unmatched_indices:\n",
    "                curr_row = current_year_data.loc[curr_idx]\n",
    "                curr_name = curr_row['name']\n",
    "                \n",
    "                best_match_idx = None\n",
    "                best_match_score = 0.0\n",
    "                \n",
    "                # Try to match with all non-abbreviated prev year records\n",
    "                for prev_idx, prev_row in prev_year_not_abbreviated.iterrows():\n",
    "                    # Compare curr_name with prev_abbreviated_name\n",
    "                    name_sim = fuzz.token_sort_ratio(curr_name, prev_row['abbreviated_name']) / 100.0\n",
    "                    \n",
    "                    # Require higher threshold for cross-ministry\n",
    "                    if name_sim >= 0.7 and name_sim > best_match_score:\n",
    "                        best_match_idx = prev_idx\n",
    "                        best_match_score = name_sim\n",
    "                \n",
    "                if best_match_idx is not None:\n",
    "                    prev_id = prev_year_data.loc[best_match_idx, 'person_id']\n",
    "                    \n",
    "                    print(f\"Abbreviated match across ministries: {curr_row['name']} ({curr_row['ministry']}) -> {prev_year_data.loc[best_match_idx, 'name']} ({prev_year_data.loc[best_match_idx, 'ministry']}, {prev_year_data.loc[best_match_idx, 'abbreviated_name']})\")\n",
    "                    \n",
    "                    current_year_person_ids[curr_idx] = prev_id\n",
    "                    used_prev_ids.add(prev_id)\n",
    "                    matched_current_indices.add(curr_idx)\n",
    "                    matches_count += 1\n",
    "            \n",
    "            print(f\"Step 4: Matched {matches_count} records using abbreviated name across ministries.\")\n",
    "        \n",
    "        ### ASSIGN NEW IDS FOR REMAINING UNMATCHED RECORDS ####\n",
    "        \n",
    "        # Identify final unmatched records\n",
    "        unmatched_indices = current_year_data.index[~current_year_data.index.isin(matched_current_indices)]\n",
    "        \n",
    "        if len(unmatched_indices) > 0:\n",
    "            # Get max person ID used so far\n",
    "            max_id = df_panel['person_id'].max()\n",
    "            \n",
    "            # Assign new sequential IDs\n",
    "            for i, idx in enumerate(unmatched_indices):\n",
    "                current_year_person_ids[idx] = max_id + i + 1\n",
    "        \n",
    "        ### UPDATE MAIN DATAFRAME WITH PERSON IDS ###\n",
    "        \n",
    "        # Map back to original indices\n",
    "        for curr_idx, person_id in current_year_person_ids.items():\n",
    "            if pd.notna(person_id):\n",
    "                orig_idx = orig_indices[curr_idx]\n",
    "                df_panel.loc[orig_idx, 'person_id'] = int(person_id)\n",
    "        \n",
    "        # Print matching summary\n",
    "        matched_count = len(current_year_data) - len(unmatched_indices)\n",
    "        new_count = len(unmatched_indices)\n",
    "        print(f\"Year {current_year}: matched {matched_count} records with previous year. Added {new_count} new IDs.\")\n",
    "        \n",
    "        # Print details of new entries\n",
    "        if new_count > 0:\n",
    "            print(\"New entries:\")\n",
    "            for idx in unmatched_indices:\n",
    "                orig_idx = orig_indices[idx]\n",
    "                row = current_year_data.loc[idx]\n",
    "                print(f\"  - {row['name']} ({row['ministry']}, {row['position']})\")\n",
    "    \n",
    "    # Ensure person_id is integer\n",
    "    df_panel['person_id'] = df_panel['person_id'].astype(int)\n",
    "    \n",
    "    # Verify the unique constraint - each person should appear at most once per year\n",
    "    for year in years:\n",
    "        year_data = df_panel[df_panel['year'] == year]\n",
    "        id_counts = year_data['person_id'].value_counts()\n",
    "        \n",
    "        if any(id_counts > 1):\n",
    "            duplicate_ids = id_counts[id_counts > 1].index.tolist()\n",
    "            print(f\"WARNING: Constraint violation - person IDs appearing multiple times in year {year}: {duplicate_ids}\")\n",
    "            \n",
    "            # Fix any duplicates\n",
    "            for dup_id in duplicate_ids:\n",
    "                dup_indices = year_data[year_data['person_id'] == dup_id].index[1:]\n",
    "                for i, idx in enumerate(dup_indices):\n",
    "                    max_id = df_panel['person_id'].max()\n",
    "                    df_panel.loc[idx, 'person_id'] = max_id + 1\n",
    "                    print(f\"Assigned new ID {max_id + 1} to duplicate record.\")\n",
    "    \n",
    "    return df_panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70a450a-3ce6-4fdc-bba2-edd634c803ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "panel = create_panel_data(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
